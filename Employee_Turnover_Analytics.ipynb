{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDRKdPuCac8k9TET3ol3C8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezzywd78/MS_AI_Engineer_Course/blob/main/Employee_Turnover_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAdcCtnYYIWj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46670071"
      },
      "source": [
        "# Task\n",
        "Analyze employee turnover by understanding the problem statement from `/content/1739525570_employee_turnover_problem_statement.docx`, extracting objectives, unzipping and loading the HR data from `/content/1739525599_hr_comma_sep.zip`, and outlining a plan for exploratory data analysis, data cleaning, and feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6028e0f6"
      },
      "source": [
        "## Read Problem Statement Document\n",
        "\n",
        "### Subtask:\n",
        "Load and read the content from the `/content/1739525570_employee_turnover_problem_statement.docx` file to understand the context of the employee turnover problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "665f0252"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to install the `python-docx` library, which is necessary to read the `.docx` file specified in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "c3b444b8",
        "outputId": "6c5c8934-df9d-45ff-c748-91cd68423581"
      },
      "source": [
        "pip install python-docx\n",
        "print(\"python-docx installed successfully\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-216443323.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-216443323.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install python-docx\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64d7c348"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `pip install` needs to be prefixed with `!` to be executed as a shell command within a Colab notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "358dd465",
        "outputId": "f18a9d53-a280-47cb-969f-9740cb395327"
      },
      "source": [
        "!pip install python-docx\n",
        "print(\"python-docx installed successfully\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n",
            "python-docx installed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d99e288"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `python-docx` library is installed, I will import the `Document` class, load the specified `.docx` file, extract all the text content by iterating through its paragraphs, and then print the extracted text to fulfill the subtask's requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8546075a",
        "outputId": "66000897-43ff-4d00-f6b1-33044650c4eb"
      },
      "source": [
        "from docx import Document\n",
        "\n",
        "doc_path = '/content/1739525570_employee_turnover_problem_statement.docx'\n",
        "document = Document(doc_path)\n",
        "\n",
        "problem_statement_text = []\n",
        "for para in document.paragraphs:\n",
        "    problem_statement_text.append(para.text)\n",
        "\n",
        "full_text = '\\n'.join(problem_statement_text)\n",
        "print(full_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Machine Learning\n",
            "Course-End Project Problem Statement\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Employee Turnover Analytics\n",
            "\n",
            "Project Statement:\n",
            "Portobello Tech is an app innovator who has devised an intelligent way of predicting employee turnover within the company. It periodically evaluates employees' work details, including the number of projects they worked on, average monthly working hours, time spent in the company, promotions in the last five years, and salary level.\n",
            "Data from prior evaluations shows the employees’ satisfaction in the workplace. The data could be used to identify patterns in work style and their interest in continuing to work for the company. \n",
            "The HR Department owns the data and uses it to predict employee turnover. Employee turnover refers to the total number of workers who leave a company over time.\n",
            "As the ML Developer assigned to the HR Department, you have been asked to create ML programs to:\n",
            "Perform data quality checks by checking for missing values, if any.\n",
            "Understand what factors contributed most to employee turnover at EDA.\n",
            "Perform clustering of employees who left based on their satisfaction and evaluation.\n",
            "Handle the left Class Imbalance using the SMOTE technique.\n",
            "Perform k-fold cross-validation model training and evaluate performance. \n",
            "Identify the best model and justify the evaluation metrics used. \n",
            "Suggest various retention strategies for targeted employees.\n",
            "Data will be modified from: \n",
            "https://www.kaggle.com/liujiaqi/hr-comma-sepcsv\n",
            "Perform the following steps:\n",
            "Perform data quality checks by checking for missing values, if any.\n",
            "Understand what factors contributed most to employee turnover at EDA.\n",
            "Draw a heatmap of the correlation matrix between all numerical features or columns in the data.\n",
            "Draw the distribution plot of:\n",
            "Employee Satisfaction (use column satisfaction_level)\n",
            "Employee Evaluation (use column last_evaluation)\n",
            "Employee Average Monthly Hours (use column average_montly_hours)\n",
            "Draw the bar plot of the employee project count of both employees who left and stayed in the organization (use column number_project and hue column left), and give your inferences from the plot.\n",
            "Perform clustering of employees who left based on their satisfaction and evaluation.\n",
            "Choose columns satisfaction_level, last_evaluation, and left.\n",
            "Do K-means clustering of employees who left the company into 3 clusters?\n",
            "Based on the satisfaction and evaluation factors, give your thoughts on the employee clusters.\n",
            "Handle the left Class Imbalance using the SMOTE technique.\n",
            "Pre-process the data by converting categorical columns to numerical columns by:\n",
            "Separating categorical variables and numeric variables\n",
            "Applying get_dummies() to the categorical variables\n",
            "Combining categorical variables and numeric variables\n",
            "Do the stratified split of the dataset to train and test in the ratio 80:20 with random_state=123.\n",
            "Upsample the train dataset using the SMOTE technique from the imblearn module.\n",
            "Perform 5-fold cross-validation model training and evaluate performance.\n",
            "Train a logistic regression model, apply a 5-fold CV, and plot the classification report.\n",
            "Train a Random Forest Classifier model, apply the 5-fold CV, and plot the classification report.\n",
            "Train a Gradient Boosting Classifier model, apply the 5-fold CV, and plot the classification report.\n",
            "Identify the best model and justify the evaluation metrics used.\n",
            "Find the ROC/AUC for each model and plot the ROC curve.\n",
            "Find the confusion matrix for each of the models.\n",
            "Explain which metric needs to be used from the confusion matrix: Recall or Precision?\n",
            "Suggest various retention strategies for targeted employees.\n",
            "Using the best model, predict the probability of employee turnover in the test data.\n",
            "Based on the probability score range below, categorize the employees into four zones and suggest your thoughts on the retention strategies for each zone.\n",
            "Safe Zone (Green) (Score < 20%)\n",
            "Low-Risk Zone (Yellow) (20% < Score < 60%)\n",
            "Medium-Risk Zone (Orange) (60% < Score < 90%)\n",
            "High-Risk Zone (Red) (Score > 90%).\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84c6f6ed"
      },
      "source": [
        "## Summarize Objectives and Requirements\n",
        "\n",
        "### Subtask:\n",
        "Extract and summarize the key objectives, requirements, and scope of the employee turnover problem as defined in the document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c1ff0c8"
      },
      "source": [
        "### Summary of Objectives and Requirements\n",
        "\n",
        "The main goal of this project for Portobello Tech's HR department is to **predict employee turnover within the company by creating Machine Learning programs**.\n",
        "\n",
        "**Specific Tasks and Requirements:**\n",
        "\n",
        "1.  **Data Quality Checks**: Perform checks for missing values.\n",
        "2.  **Exploratory Data Analysis (EDA)**:\n",
        "    *   Understand factors contributing to employee turnover.\n",
        "    *   Draw a heatmap of the correlation matrix for numerical features.\n",
        "    *   Draw distribution plots for `satisfaction_level`, `last_evaluation`, and `average_montly_hours`.\n",
        "    *   Draw a bar plot for `number_project` comparing employees who left and stayed.\n",
        "3.  **Clustering**: Perform K-means clustering (3 clusters) on employees who left, based on `satisfaction_level` and `last_evaluation`.\n",
        "4.  **Handle Class Imbalance**: Address the imbalance in the 'left' class using the SMOTE technique.\n",
        "    *   Pre-process data by converting categorical columns to numerical using `get_dummies()`.\n",
        "    *   Perform a stratified split of the dataset (80:20 train-test ratio, `random_state=123`).\n",
        "    *   Upsample the training dataset using SMOTE.\n",
        "5.  **Model Training and Evaluation (5-fold Cross-Validation)**:\n",
        "    *   Train a Logistic Regression model.\n",
        "    *   Train a Random Forest Classifier model.\n",
        "    *   Train a Gradient Boosting Classifier model.\n",
        "    *   Plot classification reports for each model.\n",
        "6.  **Identify Best Model**: Determine the best model and justify evaluation metrics.\n",
        "    *   Find and plot ROC/AUC curves for each model.\n",
        "    *   Find confusion matrices for each model.\n",
        "    *   Explain the appropriate metric (Recall or Precision) from the confusion matrix.\n",
        "7.  **Suggest Retention Strategies**: Using the best model, predict employee turnover probability and categorize employees into four zones (Safe, Low-Risk, Medium-Risk, High-Risk) to suggest targeted retention strategies.\n",
        "\n",
        "**Scope of the Project:**\n",
        "The project will utilize employee work details including `number_project`, `average_montly_hours`, `time_spend_company`, `promotion_last_5years`, `salary` level, employee `satisfaction_level`, and `last_evaluation`. The objective is to identify patterns in work style and employee interest in continuing with the company, using data provided by the HR Department to predict and address employee turnover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f092339"
      },
      "source": [
        "## Unzip HR Data\n",
        "\n",
        "### Subtask:\n",
        "Unzip the `/content/1739525599_hr_comma_sep.zip` file to access the HR data, which will be used for subsequent analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdc5819f"
      },
      "source": [
        "**Reasoning**:\n",
        "To unzip the file, I will use the `zipfile` module. The code will import `zipfile`, specify the path to the zip file, create a ZipFile object, extract all its contents to the current directory, and then close the zip file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "163d7ddf",
        "outputId": "926d20f7-dd25-4c1b-de6d-d7fe8232ac75"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = '/content/1739525599_hr_comma_sep.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "\n",
        "print(f\"'{zip_file_path}' unzipped successfully to './'\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/1739525599_hr_comma_sep.zip' unzipped successfully to './'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c9710df"
      },
      "source": [
        "## Load HR Data\n",
        "\n",
        "### Subtask:\n",
        "Load the unzipped HR data into a pandas DataFrame, preparing it for analysis related to employee turnover.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "914c6d3f"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import the pandas library, which is essential for data manipulation and loading the CSV file into a DataFrame. Then, I will load the 'HR_comma_sep.csv' file into a DataFrame named `df` to make the data accessible for analysis. Finally, displaying the first five rows of the DataFrame will allow me to quickly verify that the data has been loaded correctly and to get a preliminary look at its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "42da1a44",
        "outputId": "542360e9-ebba-450a-e61e-f6335f927b5d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('HR_comma_sep.csv')\n",
        "\n",
        "print(\"HR data loaded successfully. Displaying the first 5 rows:\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HR data loaded successfully. Displaying the first 5 rows:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
              "0                0.38             0.53               2                   157   \n",
              "1                0.80             0.86               5                   262   \n",
              "2                0.11             0.88               7                   272   \n",
              "3                0.72             0.87               5                   223   \n",
              "4                0.37             0.52               2                   159   \n",
              "\n",
              "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
              "0                   3              0     1                      0  sales   \n",
              "1                   6              0     1                      0  sales   \n",
              "2                   4              0     1                      0  sales   \n",
              "3                   5              0     1                      0  sales   \n",
              "4                   3              0     1                      0  sales   \n",
              "\n",
              "   salary  \n",
              "0     low  \n",
              "1  medium  \n",
              "2  medium  \n",
              "3     low  \n",
              "4     low  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06ffe8d2-9000-4774-a7c6-1f1237bd6869\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>satisfaction_level</th>\n",
              "      <th>last_evaluation</th>\n",
              "      <th>number_project</th>\n",
              "      <th>average_montly_hours</th>\n",
              "      <th>time_spend_company</th>\n",
              "      <th>Work_accident</th>\n",
              "      <th>left</th>\n",
              "      <th>promotion_last_5years</th>\n",
              "      <th>sales</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>5</td>\n",
              "      <td>262</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.88</td>\n",
              "      <td>7</td>\n",
              "      <td>272</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.87</td>\n",
              "      <td>5</td>\n",
              "      <td>223</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2</td>\n",
              "      <td>159</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06ffe8d2-9000-4774-a7c6-1f1237bd6869')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06ffe8d2-9000-4774-a7c6-1f1237bd6869 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06ffe8d2-9000-4774-a7c6-1f1237bd6869');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14999,\n  \"fields\": [\n    {\n      \"column\": \"satisfaction_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2486306510611418,\n        \"min\": 0.09,\n        \"max\": 1.0,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          0.83,\n          0.13,\n          0.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_evaluation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17116911062327592,\n        \"min\": 0.36,\n        \"max\": 1.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.66,\n          0.44,\n          0.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_project\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_montly_hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 96,\n        \"max\": 310,\n        \"num_unique_values\": 215,\n        \"samples\": [\n          118,\n          112,\n          222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_spend_company\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6,\n          8,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Work_accident\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"left\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"promotion_last_5years\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sales\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"marketing\",\n          \"accounting\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"low\",\n          \"medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da3ed273"
      },
      "source": [
        "## Outline Subsequent Analysis Steps\n",
        "\n",
        "### Subtask:\n",
        "Based on the problem statement and the available HR data, outline a detailed plan for initial data analysis, including exploratory data analysis (EDA) to identify potential factors contributing to employee turnover, data cleaning, and feature engineering considerations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaeb98bb"
      },
      "source": [
        "### Detailed Plan for Initial Data Analysis\n",
        "\n",
        "#### 1. Initial Data Inspection:\n",
        "*   **Inspect DataFrame Dimensions**: Use `df.shape` to understand the number of rows and columns in the dataset.\n",
        "*   **Review Data Types and Non-Null Values**: Use `df.info()` to get a summary of the DataFrame, including data types of each column and the count of non-null values, which is crucial for identifying potential data quality issues.\n",
        "*   **Generate Descriptive Statistics**: Apply `df.describe()` to obtain statistical summaries (count, mean, std, min, 25%, 50%, 75%, max) for all numerical columns, providing insights into their distribution and potential outliers.\n",
        "*   **Check for Missing Values**: Use `df.isnull().sum()` to calculate the total number of missing values for each column. This will directly address the problem statement's requirement to 'Perform data quality checks by checking for missing values, if any.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3a8743d"
      },
      "source": [
        "#### 2. Exploratory Data Analysis (EDA) Plan:\n",
        "*   **Correlation Analysis**: Outline the steps to create a correlation matrix for all numerical features and visualize it using a heatmap to identify relationships between variables, especially with the 'left' column.\n",
        "*   **Distribution Analysis**: Plan to create distribution plots for `satisfaction_level`, `last_evaluation`, and `average_montly_hours` to understand their spread and characteristics.\n",
        "*   **Comparative Analysis**: Outline the steps to generate a bar plot comparing the `number_project` for employees who left versus those who stayed, to infer potential patterns related to project workload and turnover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5c50b5e"
      },
      "source": [
        "#### 3. Data Cleaning Plan:\n",
        "*   Based on the missing value check, formulate a strategy for handling any identified missing data (e.g., imputation, removal, or further investigation), though the problem statement mentions checking for missing values, implying a quality check rather than an immediate cleaning action if none exist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1bc35b3"
      },
      "source": [
        "#### 4. Feature Engineering Considerations:\n",
        "*   Detail the plan to identify categorical columns in the dataset and convert them into numerical representations using one-hot encoding (e.g., `pd.get_dummies()`), as specified in the problem statement for preprocessing before handling class imbalance.\n",
        "*   Consider if any new features might be beneficial for modeling, though the problem statement heavily focuses on existing features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "900084b5"
      },
      "source": [
        "#### 4. Feature Engineering Considerations:\n",
        "*   Detail the plan to identify categorical columns in the dataset and convert them into numerical representations using one-hot encoding (e.g., `pd.get_dummies()`), as specified in the problem statement for preprocessing before handling class imbalance.\n",
        "*   Consider if any new features might be beneficial for modeling, though the problem statement heavily focuses on existing features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bac1b74"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the understanding of the problem statement, the key requirements, and the proposed analytical steps to address employee turnover.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "797057c6"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The problem statement was successfully extracted from the provided document, revealing Portobello Tech's goal to predict employee turnover using machine learning.\n",
        "*   A comprehensive list of specific tasks was identified from the problem statement, including data quality checks, Exploratory Data Analysis (EDA), K-means clustering, handling class imbalance with SMOTE, training and evaluating multiple classification models (Logistic Regression, Random Forest, Gradient Boosting), identifying the best model, and suggesting retention strategies.\n",
        "*   The HR dataset was successfully prepared by unzipping the `hr_comma_sep.zip` file and loading the `HR_comma_sep.csv` into a pandas DataFrame.\n",
        "*   A detailed plan for subsequent analysis steps was outlined, covering:\n",
        "    *   **Initial Data Inspection**: Checking DataFrame dimensions, data types, non-null values, descriptive statistics, and missing values.\n",
        "    *   **Exploratory Data Analysis**: Performing correlation analysis with heatmaps, distribution plots for `satisfaction_level`, `last_evaluation`, and `average_montly_hours`, and comparative bar plots for `number_project` between employees who left and stayed.\n",
        "    *   **Data Cleaning**: Strategizing for handling any identified missing data.\n",
        "    *   **Feature Engineering**: Converting categorical columns to numerical using one-hot encoding (`pd.get_dummies()`).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The detailed plan aligns directly with the project objectives, ensuring that all aspects of the problem statement, from data understanding to model development and strategy formulation, will be addressed systematically.\n",
        "*   The immediate next step is to execute the outlined \"Initial Data Inspection\" and \"Exploratory Data Analysis\" steps on the loaded HR data to gain initial insights and identify data quality issues.\n"
      ]
    }
  ]
}